{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "X = np.load('../Dvara/X_10_2_re.npy')\n",
    "y = np.load('../Dvara/y_10_2_re.npy')\n",
    "#y = (X[:,-1,-1]>=5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_pass1 = np.isnan(X).sum(axis=1).sum(axis=1)\n",
    "ind_pass2 = [i==0 for i in ind_pass1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[ind_pass2]\n",
    "y = y[ind_pass2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_cols = ['active_loans_count', 'opened_loans_count', 'closed_loans_count', 'churn', 'outstanding_loans_end', 'cross_bor', 'outstanding_loans_beginning', 'income_annual', 'expense_quarter', 'emi', 'dpd']\n",
    "\n",
    "# acc_cols = [7,8,10]\n",
    "# X = X[:,:,acc_cols]\n",
    "\n",
    "col1 = [0,1,2,3,4,5,6]\n",
    "col2 = [7,8,9]\n",
    "col3 = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, GRU, Input, Dropout, Lambda, TimeDistributed, Concatenate, Maximum\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=4)\n",
    "\n",
    "X_train1 = X_train[:,:,col1]\n",
    "X_train2 = X_train[:,:,col2]\n",
    "X_train3 = (X_train[:,:,col3]>=5)*1\n",
    "\n",
    "X_test1 = X_test[:,:,col1]\n",
    "X_test2 = X_test[:,:,col2]\n",
    "X_test3 = (X_test[:,:,col3]>=5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67845, 10, 1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = Input(shape=(X_train1.shape[1], X_train1.shape[2]))\n",
    "inp2 = Input(shape=(X_train2.shape[1], X_train2.shape[2]))\n",
    "inp3 = Input(shape=(X_train3.shape[1], X_train3.shape[2]))\n",
    "\n",
    "layer1_1 = LSTM(64, activation='tanh', recurrent_dropout=0.3, return_sequences=True)(inp1)\n",
    "layer2_1 = GRU(32, activation='tanh', recurrent_dropout=0.3)(layer1_1)\n",
    "\n",
    "layer1_2 = LSTM(64, activation='tanh', recurrent_dropout=0.3, return_sequences=True)(inp2)\n",
    "layer2_2 = GRU(32, activation='tanh', recurrent_dropout=0.3)(layer1_2)\n",
    "\n",
    "layer1_3 = LSTM(64, activation='tanh', recurrent_dropout=0.3, return_sequences=True)(inp3)\n",
    "layer2_3 = GRU(64, activation='tanh', recurrent_dropout=0.3)(layer1_3)\n",
    "\n",
    "layer2 = Concatenate()([layer2_1, layer2_2])\n",
    "layer3 = Maximum()([layer2, layer2_3])\n",
    "\n",
    "layer4 = Dropout(0.4)(layer3)\n",
    "layer5 = Dense(32, activation = 'tanh')(layer4)\n",
    "layer6 = Dropout(0.4)(layer5)\n",
    "layer7 = Dense(8, activation='tanh')(layer6)\n",
    "out = Dense(1, activation = 'sigmoid')(layer7)\n",
    "\n",
    "model = Model(inputs=[inp1, inp2, inp3], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(layer):\n",
    "\n",
    "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
    "    def loss(y_true,y_pred):\n",
    "        return K.binary_crossentropy(y_true, y_pred) + 5*K.mean(layer[:,-1,0]*K.square(y_pred - layer[:,-1,0]), axis=-1)\n",
    "        #return K.mean(K.square(y_pred - y_true) + layer[:,-1,0]*K.square(y_pred - layer[:,-1,0]), axis=-1)\n",
    "        #return K.mean(K.square(y_pred - y_true) + 10*y_true*K.square(y_pred - y_true), axis=-1)\n",
    "   \n",
    "    # Return a function\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "          loss=custom_loss(inp3),\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           (None, 10, 7)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           (None, 10, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                  (None, 10, 64)       18432       input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                  (None, 10, 64)       17408       input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, 10, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_25 (GRU)                    (None, 32)           9312        lstm_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_26 (GRU)                    (None, 32)           9312        lstm_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  (None, 10, 64)       16896       input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 64)           0           gru_25[0][0]                     \n",
      "                                                                 gru_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru_27 (GRU)                    (None, 64)           24768       lstm_27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_9 (Maximum)             (None, 64)           0           concatenate_9[0][0]              \n",
      "                                                                 gru_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 64)           0           maximum_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 32)           2080        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32)           0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 8)            264         dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1)            9           dense_26[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 98,481\n",
      "Trainable params: 98,481\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 67845 samples, validate on 22615 samples\n",
      "Epoch 1/50\n",
      "67845/67845 [==============================] - 358s 5ms/step - loss: 0.7722 - acc: 0.9485 - val_loss: 0.7675 - val_acc: 0.9557\n",
      "Epoch 2/50\n",
      "67845/67845 [==============================] - 282s 4ms/step - loss: 0.7704 - acc: 0.9577 - val_loss: 0.7688 - val_acc: 0.9564\n",
      "Epoch 3/50\n",
      "67845/67845 [==============================] - 282s 4ms/step - loss: 0.7698 - acc: 0.9575 - val_loss: 0.7686 - val_acc: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22489f63438>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=2)]\n",
    "model.fit([X_train1, X_train2, X_train3], y_train, batch_size = 128, epochs=50, validation_data=[[X_test1, X_test2, X_test3], y_test], shuffle=True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and get lables for the test data\n",
    "y_test_pred = (model.predict([X_test1, X_test2, X_test3])>=0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9545434446164051\n",
      "\n",
      "Test F1 score:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.97      0.97     17834\n",
      "        1.0       0.89      0.90      0.89      4781\n",
      "\n",
      "avg / total       0.95      0.95      0.95     22615\n",
      "\n",
      "\n",
      "Test confusion matrix:\n",
      " [[17275   559]\n",
      " [  469  4312]]\n"
     ]
    }
   ],
   "source": [
    "# Import packages for calculating metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"\\nTest F1 score:\\n\", classification_report(y_test, y_test_pred))\n",
    "print(\"\\nTest confusion matrix:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "X_knn_val = np.load('Validation_Dataset_for_Autoencoder.npy')\n",
    "y_knn_val_new = ((X_knn_val[:,-n:,-1]>=5).sum(axis=1)>=1)*1\n",
    "arr_hhs = np.load('val_labels145.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_rej = np.logical_and(arr_hhs==0, y_knn_val_new==1)\n",
    "ind_pass = [i==False for i in ind_rej]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_knn_val = X_knn_val[ind_pass,:,:]\n",
    "y_knn_val_new = y_knn_val_new[ind_pass]\n",
    "arr_hhs = arr_hhs[ind_pass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_knn_val1 = X_knn_val[:,:,col1]\n",
    "X_knn_val2 = X_knn_val[:,:,col2]\n",
    "X_knn_val3 = X_knn_val[:,:,col3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_prob = model.predict([X_knn_val1, X_knn_val2, X_knn_val3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = (val_pred_prob>=0.355)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5656041512231282\n",
      "\n",
      "Test F1 score:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.40      0.44       566\n",
      "          1       0.61      0.68      0.65       783\n",
      "\n",
      "avg / total       0.56      0.57      0.56      1349\n",
      "\n",
      "\n",
      "Test confusion matrix:\n",
      " [[227 339]\n",
      " [247 536]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "print(\"Test Accuracy:\", accuracy_score(arr_hhs, val_pred))\n",
    "print(\"\\nTest F1 score:\\n\", classification_report(arr_hhs, val_pred))\n",
    "print(\"\\nTest confusion matrix:\\n\", confusion_matrix(arr_hhs, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2249a609a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(val_pred_prob, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
